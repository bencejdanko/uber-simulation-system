services:
  kong:
      # --- Build the custom image instead of pulling ---
      build:
        context: ./kong  # Directory containing the Dockerfile and plugin source
        dockerfile: kong.Dockerfile # The name of the Dockerfile within the context
      # image: kong/kong-gateway:latest # Remove this line
      # --- End Build Section ---

      container_name: kong-gateway
      environment:
        KONG_DATABASE: 'off'
        KONG_DECLARATIVE_CONFIG: /etc/kong/kong.yaml
        KONG_PROXY_LISTEN: 0.0.0.0:8000
        KONG_ADMIN_LISTEN: 0.0.0.0:8001
        KONG_LOG_LEVEL: debug # Keep for debugging plugin
        KONG_DECLARATIVE_CONFIG_SCHEMA_CACHE: 'off'

        # --- REMOVE THESE ---
        # KONG_PLUGINS: bundled,jwt,jwt-claims-to-headers # Now set in the Dockerfile ENV
        # KONG_LUA_PACKAGE_PATH: /usr/local/kong/plugins/?.lua;; # Not needed if using standard path
        # --- End Removals ---

        # KONG_DNS_ORDER: LAST,SRV,A,CNAME # Uncomment if needed

      ports:
        - "${GATEWAY_PORT:-80}:8000" # Use default 80 if GATEWAY_PORT not set
        - "${GATEWAY_ADMIN_PORT:-8001}:8001" # Use default 8001 if GATEWAY_ADMIN_PORT not set
      volumes:
        # Mount the configuration file ONLY
        - ./kong/config/kong.yaml:/etc/kong/kong.yaml:ro
      networks:
        - app-network
      healthcheck:
        test: ["CMD", "kong", "health"]
        interval: 10s
        timeout: 5s
        retries: 5
        start_period: 15s # Give time for config load, especially first time

  # --- Apache Zookeeper ---
  zookeeper:
    image: bitnami/zookeeper:3.8
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    volumes:
      - zookeeper_data:/bitnami/zookeeper
    networks:
      - app-network

  # --- Apache Kafka Broker ---
  kafka:
    image: bitnami/kafka:3.5
    # ports:
      # Port for clients OUTSIDE the Docker network (maps to EXTERNAL listener's container port 9094)
      # - "${KAFKA_PORT}:9094"
      # Port 9092 is used INTERNALLY by containers and doesn't need to be exposed to the host.
      # We explicitly bind to it inside the container using KAFKA_CFG_LISTENERS.
    environment:
      # --- Zookeeper Connection ---
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181

      # --- Listener Configuration (CRITICAL for Connectivity) ---
      # 1. Define Listener Names and Security Protocols
      #    Maps listener names (INTERNAL, EXTERNAL) to security protocols (PLAINTEXT).
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT

      # 2. Define Listeners the Broker Should *Bind* To
      #    Tells Kafka to listen on specific ports using the names defined above.
      #    INTERNAL listener binds to port 9092 on all container interfaces (accessible within Docker network).
      #    EXTERNAL listener binds to port 9094 on all container interfaces (accessible via the mapped port 9094 on the host).
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:9094
      # Note: Using :<port> or 0.0.0.0:<port> makes Kafka listen on all available network interfaces within the container.

      # 3. Define Advertised Listeners for Clients
      #    Tells clients *how* to connect to the broker, depending on where the client is.
      #    Clients inside the Docker network use the INTERNAL listener via the service name 'kafka' and port 9092.
      #    Clients outside the Docker network (on the host) use the EXTERNAL listener via 'localhost' and the mapped port 9094.
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:9094

      # 4. Define Internal Communication Listener
      #    Which listener Kafka uses for its own internal communication (inter-broker, controller).
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL

      # --- Topic Settings ---
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_CFG_NUM_PARTITIONS=3 # Default partitions for auto-created topics

      # --- Automatic Topic Creation (Bitnami Feature) ---
      # Format: "TopicName1:Partitions:ReplicationFactor,TopicName2:Partitions:ReplicationFactor"
      - KAFKA_CREATE_TOPICS="user.registered:1:1,another.topic:3:1,yet.another.topic:1:1" # Add your topics here

      # --- Other Settings ---
      - ALLOW_PLAINTEXT_LISTENER=yes # Required by Bitnami for PLAINTEXT listeners
      - KAFKA_CFG_GROUP_INITIAL_REBALANCE_DELAY_MS=100 # Faster dev restarts

    volumes:
      - kafka_data:/bitnami/kafka
    depends_on:
      - zookeeper
    networks:
      - app-network

  # --- Auth Service ---
  auth-service:
    build:
      context: ./services/auth # Path relative to docker-compose.yml
      dockerfile: Dockerfile
    # No need to expose the auth service port unless you want to access it directly
    # ports:
    #   - "3000:3000" # Map container port 3000 to host port 3000
    environment:
      # Server configuration
      - PORT=3000
      
      # MongoDB configuration
      - MONGODB_URI=${MONGODB_URI}
      
      # JWT configuration
      - ACCESS_TOKEN_PRIVATE_KEY_PATH=/usr/src/app/private.pem
      - ACCESS_TOKEN_PUBLIC_KEY_PATH=/usr/src/app/public.pem
      - ACCESS_TOKEN_LIFE=15m
      - ACCESS_TOKEN_KID=auth-service-key-1
      - JWT_ISSUER=https://my-auth-service.com
      
      # Kafka configuration
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=auth-service-producer
      - KAFKA_USER_REGISTERED_TOPIC=user.registered
      
      # Hashing configuration
      - BCRYPT_SALT_ROUNDS=10
    
    volumes:
      # Mount the key files
      - ./keys/private.pem:/usr/src/app/private.pem:ro
      - ./keys/public.pem:/usr/src/app/public.pem:ro
    
    depends_on:
      - kafka
      # - mongo # Added dependency on MongoDB
    networks:
      - app-network

  driver-service:
    build:
      context: ./services/driver # Path relative to docker-compose.yml
      dockerfile: Dockerfile
    # No need to expose the driver service port unless you want to access it directly
    # ports:
    #   - "3001:3001" # Map container port 3001 to host port 3001
    environment:
      - PORT=3001
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=driver-service-consumer
      - KAFKA_USER_REGISTERED_TOPIC=user.registered
      - MONGODB_URI=${MONGODB_URI}
      
    depends_on:
      - kafka
    networks:
      - app-network

  # --- MongoDB Service (Added) ---
  # mongo:
  #   image: mongo:6.0
  #   container_name: mongodb
  #   ports:
  #     - "27017:27017"
  #   volumes:
  #     - mongodb_data:/data/db
  #   networks:
  #     - app-network
  #   # Optional: Add health check
  #   healthcheck:
  #     test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 3
  #     start_period: 20s

volumes:
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local
  # mongodb_data:
  #   driver: local

networks:
  app-network:
    driver: bridge